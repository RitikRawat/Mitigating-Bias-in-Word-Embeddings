{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "from collections import defaultdict\n",
        "glove_path = '/content/drive/MyDrive/word_embeddings/glove/glove.6B.300d.txt'\n",
        "def load_glove_embeddings(glove_path):\n",
        "    embeddings = {}\n",
        "    with open(glove_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "glove_embeddings = load_glove_embeddings(glove_path)\n",
        "print(f\"Loaded {len(glove_embeddings)} word vectors.\")\n",
        "def normalize_embeddings(embeddings):\n",
        "    norm_embeddings = {}\n",
        "    for word, vec in embeddings.items():\n",
        "        norm_embeddings[word] = vec / np.linalg.norm(vec)\n",
        "    return norm_embeddings\n",
        "\n",
        "# Normalize GloVe embeddings\n",
        "normalized_glove_embeddings = normalize_embeddings(glove_embeddings)\n",
        "occupation_words = []\n",
        "with open('words.txt','r') as file:\n",
        "  occupation_words = [line.rstrip().replace(' ','-').lower() for line in file]\n",
        "def check_oov_words(word_list, embeddings):\n",
        "    oov_words = []\n",
        "    for word in word_list:\n",
        "        if word not in embeddings:\n",
        "            oov_words.append(word)\n",
        "    return oov_words\n",
        "\n",
        "oov_gendered = check_oov_words(gendered_words, normalized_glove_embeddings)\n",
        "oov_occupation = check_oov_words(occupation_words, normalized_glove_embeddings)\n",
        "\n",
        "print(f\"OOV gendered words: {oov_gendered}\")\n",
        "print(f\"OOV occupation words: {oov_occupation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT-QKPWkXdGZ",
        "outputId": "c804d168-41a8-44cf-e746-ffbb5a33c1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loaded 400000 word vectors.\n",
            "OOV gendered words: []\n",
            "OOV occupation words: ['', '', '', '', '', '', 'flight-attendant', '', 'social-worker', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'police-officer', '', 'security-guard', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'data-scientist', '', 'data-analyst', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'office-assistant', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "occupation_words =set(occupation_words)\n",
        "oov_occupation =  set(oov_occupation)\n",
        "occupation_words = occupation_words - oov_occupation"
      ],
      "metadata": {
        "id": "bEglAfLxbfH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(occupation_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGnLd0qrb0FN",
        "outputId": "f9923051-0ccd-4ef9-ac23-c576209ed1fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "def pca(matrix):\n",
        "  n_components = 10\n",
        "  pca = PCA(n_components=n_components)\n",
        "  principal_components = pca.fit_transform(matrix)\n",
        "  principal_component_vector = pca.components_[0]\n",
        "  #principal_df = pd.DataFrame(principal_components, columns=[f\"PC{i+1}\" for i in range(n_components)])\n",
        "  print(\"Explained variance ratio of each component:\", pca.explained_variance_ratio_)\n",
        "  #print(\"Principal Components:\\n\", principal_df)\n",
        "\n",
        "  return principal_component_vector\n",
        "\n",
        "gender_pairs = [('he', 'she'),('his','her'), ('man', 'woman'),('john','mary'),('boy', 'girl'),('himself','herself'),('son','daughter'),('guy','gal'), ('father', 'mother'), ('male','female') ]\n",
        "matrix =[]\n",
        "for a,b in gender_pairs:\n",
        "  matrix.append(normalized_glove_embeddings[b] - normalized_glove_embeddings[a])\n",
        "matrix = np.array(matrix)\n",
        "df = pca(matrix)\n",
        "gender_axis = df\n",
        "from scipy.spatial.distance import cosine\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
        "    return 1 - cosine(vec1, vec2)\n",
        "def compute_gender_bias(embeddings, occupation_words, gender_axis):\n",
        "    bias_scores = {}\n",
        "    for word in occupation_words:\n",
        "            if word not in embeddings:\n",
        "              print('here')\n",
        "            similarity = cosine_similarity(embeddings[word], gender_axis)\n",
        "            bias_scores[word] = similarity\n",
        "    return bias_scores\n",
        "scores = compute_gender_bias(normalized_glove_embeddings,occupation_words,gender_axis)\n",
        "final_score =0\n",
        "for key in scores.keys():\n",
        "  final_score+=abs(scores[key])\n",
        "final_score/= len(scores)\n",
        "final_score"
      ],
      "metadata": {
        "id": "mvMjL0GUYrB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "663c9df9-635a-4b6d-d951-08124ed8f1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained variance ratio of each component: [4.0312684e-01 2.1468970e-01 1.4305896e-01 7.0180491e-02 6.0047414e-02\n",
            " 4.5551356e-02 3.2000728e-02 1.9898888e-02 1.1445663e-02 5.9663950e-15]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09191059272812405"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 3: Hard Debiasing\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Step 1: Define gendered words for subspace calculation\n",
        "gendered_words = ['he', 'she', 'man', 'woman', 'father', 'mother', 'husband', 'wife', 'boy', 'girl']\n",
        "gendered_embeddings = [normalized_glove_embeddings[word] for word in gendered_words if word in normalized_glove_embeddings]\n",
        "\n",
        "# Step 2: Compute the gender direction (subspace)\n",
        "# We use PCA (Principal Component Analysis) to find the direction of gender bias\n",
        "def compute_gender_subspace(embeddings):\n",
        "    embeddings_matrix = np.array(embeddings)\n",
        "    pca = PCA(n_components=1)\n",
        "    pca.fit(embeddings_matrix)\n",
        "    return pca.components_[0]\n",
        "\n",
        "gender_subspace = gender_axis\n",
        "\n",
        "# Step 3: Project embeddings onto the subspace and remove gender component\n",
        "def remove_gender_bias(embeddings, gender_subspace):\n",
        "    debiased_embeddings = {}\n",
        "    for word, vector in embeddings.items():\n",
        "        projection = np.dot(vector, gender_subspace) * gender_subspace\n",
        "        debiased_vector = vector - projection  # Remove the gendered component\n",
        "        debiased_embeddings[word] = debiased_vector\n",
        "    return debiased_embeddings\n",
        "\n",
        "embeddings = {word:normalized_glove_embeddings[word] for word in occupation_words}\n",
        "# Apply hard debiasing to the embeddings\n",
        "debiased_embeddings = remove_gender_bias(embeddings, gender_subspace)\n",
        "\n",
        "# Step 4: Save debiased embeddings for future use\n",
        "#np.save('/content/drive/MyDrive/word_embeddings/debiased_glove_embeddings.npy', debiased_embeddings)\n",
        "print(\"Debiased embeddings saved.\")\n",
        "\n",
        "# Step 5: Evaluate the debiased embeddings (recompute cosine similarity and WEAT score)\n",
        "\n",
        "# Compute cosine similarities for gendered word pairs after debiasing\n",
        "debiased_gender_bias_scores = compute_gender_bias(debiased_embeddings,occupation_words, gender_subspace)\n",
        "\n",
        "# Recompute WEAT score after debiasing\n",
        "#debiased_weat_score = weat_score(debiased_embeddings, target_words, attribute_words)\n",
        "\n",
        "# Display results after debiasing\n",
        "#print(\"\\nDebiased Gender Bias Cosine Similarities:\")\n",
        "#for pair, score in debiased_gender_bias_scores.items():\n",
        "#    print(f\"Similarity between {pair[0]} and {pair[1]}: {score:.4f}\")\n",
        "\n",
        "#print(f\"\\nDebiased WEAT Score for gender bias in occupations: {debiased_weat_score:.4f}\")\n",
        "sum(abs(number) for word,number in debiased_gender_bias_scores.items())/len(debiased_gender_bias_scores)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbU2w_GlS2te",
        "outputId": "2b4a8901-6aae-4d7b-b905-7f1061f6d608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Debiased embeddings saved.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.1931927629624715e-08"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from gensim.models import KeyedVectors\n",
        "from itertools import islice\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# Load pre-trained GloVe embeddings (fixed embeddings)\n",
        "def load_glove_embeddings(file_path):\n",
        "    glove_model = KeyedVectors.load_word2vec_format(file_path, binary=False)\n",
        "    return glove_model\n",
        "\n",
        "# Example: Load GloVe 300d embeddings\n",
        "\n",
        "glove_model = dict(islice(normalized_glove_embeddings.items(), 10000))\n",
        "\n",
        "# Function to get embedding for a word\n",
        "def get_embedding(word):\n",
        "    if word in glove_model:\n",
        "        return glove_model[word]\n",
        "    else:\n",
        "        return np.zeros(glove_model.vector_size)\n",
        "\n",
        "# Embedding Model (fixed pre-trained embeddings) with additional layers for feature extraction\n",
        "class FixedEmbeddingModel(nn.Module):\n",
        "    def __init__(self, embedding_dim=300):\n",
        "        super(FixedEmbeddingModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(embedding_dim, 512)\n",
        "        self.dropout1 = nn.Dropout(p=0.3)\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "        self.dropout2 = nn.Dropout(p=0.3)\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.fc4 = nn.Linear(256, embedding_dim)\n",
        "\n",
        "    def forward(self, word_embeddings):\n",
        "        x = word_embeddings\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x) + word_embeddings  # Residual connection\n",
        "        return x"
      ],
      "metadata": {
        "id": "xVzhn-BAcvBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GloveDataset(Dataset):\n",
        "    def __init__(self, glove_model):\n",
        "        self.glove_model = glove_model\n",
        "        self.words = list(glove_model.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        word = self.words[idx]\n",
        "        embedding = torch.tensor(self.glove_model[word], dtype=torch.float32)\n",
        "        return embedding"
      ],
      "metadata": {
        "id": "NPCMDRBGjHYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_embedding_autoencoder(model, glove_model, batch_size=32, epochs=100, lr=0.001):\n",
        "    dataset = GloveDataset(glove_model)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for batch in dataloader:\n",
        "            # Forward pass\n",
        "            output = model(batch)\n",
        "            loss = criterion(output, batch)  # Compute reconstruction loss\n",
        "            epoch_loss += loss.item() * batch.size(0)  # Accumulate loss for the batch\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Average loss over the entire dataset\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(dataset)}\")"
      ],
      "metadata": {
        "id": "XrqbbjA0dmNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FixedEmbeddingModel(embedding_dim=300)\n",
        "\n",
        "train_embedding_autoencoder(model, glove_model, batch_size=32, epochs=20, lr=0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4I7TyvxfLKg",
        "outputId": "1ea867c5-c8fb-4f2b-fd88-27b6cebe9ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.00012167827507655603\n",
            "Epoch 2/20, Loss: 8.112582772446331e-06\n",
            "Epoch 3/20, Loss: 4.379992613394279e-06\n",
            "Epoch 4/20, Loss: 2.759294563293224e-06\n",
            "Epoch 5/20, Loss: 1.772112929575087e-06\n",
            "Epoch 6/20, Loss: 1.0776877008538576e-06\n",
            "Epoch 7/20, Loss: 5.955111997536733e-07\n",
            "Epoch 8/20, Loss: 3.102728729800219e-07\n",
            "Epoch 9/20, Loss: 1.6353344874460162e-07\n",
            "Epoch 10/20, Loss: 8.566146744328761e-08\n",
            "Epoch 11/20, Loss: 5.093084825489314e-08\n",
            "Epoch 12/20, Loss: 3.1088684090718744e-08\n",
            "Epoch 13/20, Loss: 1.9271906919016145e-08\n",
            "Epoch 14/20, Loss: 1.3324629794198018e-08\n",
            "Epoch 15/20, Loss: 9.023412275865894e-09\n",
            "Epoch 16/20, Loss: 6.336285468933056e-09\n",
            "Epoch 17/20, Loss: 4.9383170320993486e-09\n",
            "Epoch 18/20, Loss: 3.7127947717152664e-09\n",
            "Epoch 19/20, Loss: 2.8136686371027507e-09\n",
            "Epoch 20/20, Loss: 2.151436447128674e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_model['he'].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC8FxAwmnfGw",
        "outputId": "ff78dae5-d5ea-4bdf-ea15-f532582f5735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.00116658"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_embedding_autoencoder(model, glove_model, batch_size=32):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    dataset = GloveDataset(glove_model)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "        for batch in dataloader:\n",
        "            # Forward pass\n",
        "            output = model(batch)\n",
        "            loss = criterion(output, batch)  # Compute reconstruction loss\n",
        "            total_loss += loss.item() * batch.size(0)  # Accumulate loss for the batch\n",
        "\n",
        "    # Average loss over the entire dataset\n",
        "    avg_loss = total_loss / len(dataset)\n",
        "    print(f\"Evaluation Loss (Reconstruction Error): {avg_loss}\")\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "BAzdQ0Ccn_Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate_embedding_autoencoder(model,glove_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyK2Z6p1ofRu",
        "outputId": "bf0a84e4-2a53-4fd4-d323-49d395cab64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Loss (Reconstruction Error): 3.512577190001309e-10\n",
            "3.512577190001309e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Gradient Reversal Layer (GRL)\n",
        "class GradientReversalLayer(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha=1.0):\n",
        "        ctx.alpha = alpha\n",
        "        return x.clone()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return -ctx.alpha * grad_output, None\n",
        "\n",
        "# Adversary Model (predicts sensitive attribute, e.g., gender)\n",
        "class AdversaryModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(AdversaryModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        # self.fc2 = nn.Linear(128, 256)\n",
        "        # self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        # x = torch.relu(self.fc2(x))\n",
        "        # x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "# Function to apply GRL\n",
        "def apply_grl(x, alpha=1.0):\n",
        "    return GradientReversalLayer.apply(x, alpha)\n",
        "\n",
        "# Updated Training loop for adversarial debiasing\n",
        "def train_adversarial_model(glove_model,adversary_model, embedding_model, num_epochs=100, lr=0.001, alpha=1.0):\n",
        "    # Initialize adversary model\n",
        "      # Use the dimension of GloVe embeddings\n",
        "    optimizer = optim.Adam(list(embedding_model.parameters()) + list(adversary_model.parameters()), lr=lr)\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    # Example words and gender labels (1 for male, 0 for female)\n",
        "    words = scores.keys()\n",
        "    labels = torch.tensor([scores[x] for x in scores.keys() ], dtype=torch.float32)  # Gender labels\n",
        "    labels = torch.sigmoid(labels)\n",
        "    # min_score =labels.min()\n",
        "    # max_score = labels.max()\n",
        "    # labels = (labels - min_score) / (max_score - min_score)\n",
        "    for epoch in range(num_epochs):\n",
        "        embedding_model.train()\n",
        "        adversary_model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get embeddings from glove_model, then pass through the embedding model\n",
        "        embeddings = torch.stack([torch.tensor(glove_model[word], dtype=torch.float32) for word in words])\n",
        "        transformed_embeddings = embedding_model(embeddings)  # Pass through embedding model\n",
        "\n",
        "        # Apply the Gradient Reversal Layer (GRL)\n",
        "        reversed_embeddings = apply_grl(transformed_embeddings, alpha)\n",
        "\n",
        "        # Adversary tries to predict gender from the embeddings\n",
        "        gender_predictions = adversary_model(reversed_embeddings).squeeze()\n",
        "\n",
        "        # Calculate adversarial loss\n",
        "        adversary_loss = criterion(gender_predictions, labels)\n",
        "\n",
        "        # Backpropagate and update the model\n",
        "        adversary_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print the loss every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Adversarial Loss: {adversary_loss.item():.4f}\")\n",
        "\n",
        "# Example usage\n",
        "\n"
      ],
      "metadata": {
        "id": "UMaLwXdgqHTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "model_use = copy.deepcopy(model)"
      ],
      "metadata": {
        "id": "VbXUN18pvScf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adversary_model = AdversaryModel(input_dim=300)\n",
        "train_adversarial_model(normalized_glove_embeddings,adversary_model, model_use, num_epochs=100, lr=0.0009, alpha=3.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNWLD11Yq60b",
        "outputId": "d41b10de-fd90-422e-dbcd-892fe9874892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Adversarial Loss: 0.6938\n",
            "Epoch [20/100], Adversarial Loss: 0.7019\n",
            "Epoch [30/100], Adversarial Loss: 0.6999\n",
            "Epoch [40/100], Adversarial Loss: 0.6960\n",
            "Epoch [50/100], Adversarial Loss: 0.6940\n",
            "Epoch [60/100], Adversarial Loss: 0.6978\n",
            "Epoch [70/100], Adversarial Loss: 0.7177\n",
            "Epoch [80/100], Adversarial Loss: 0.8562\n",
            "Epoch [90/100], Adversarial Loss: 0.9549\n",
            "Epoch [100/100], Adversarial Loss: 1.0867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_new_embeddings(word_embedding_dict, embedding_model):\n",
        "    # List to store the updated embeddings\n",
        "    updated_embeddings = {}\n",
        "\n",
        "    # Set the model to evaluation mode (since we're not training now)\n",
        "    embedding_model.eval()\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        for word, embedding in word_embedding_dict.items():\n",
        "            # Convert the embedding to a torch tensor\n",
        "            embedding_tensor = torch.tensor(embedding, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "            # Forward pass through the trained model\n",
        "            updated_embedding = embedding_model(embedding_tensor)  # Model expects a batch, so pass as tensor\n",
        "\n",
        "            # Store the updated embedding back into the dictionary\n",
        "            updated_embeddings[word] = updated_embedding.squeeze(0).numpy()  # Convert tensor to numpy array and remove batch dimension\n",
        "\n",
        "    return updated_embeddings\n"
      ],
      "metadata": {
        "id": "fx1L9v1lwwye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oc_embeddings = {word:normalized_glove_embeddings[word] for word in occupation_words}"
      ],
      "metadata": {
        "id": "LHdlIbuCww18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_embeddings = get_new_embeddings(oc_embeddings, model_use)"
      ],
      "metadata": {
        "id": "G2EqMbYVxeqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_scores = compute_gender_bias(updated_embeddings,occupation_words,gender_axis)\n",
        "final_score =0\n",
        "for key in new_scores.keys():\n",
        "  final_score+=abs(new_scores[key])\n",
        "final_score/= len(new_scores)\n",
        "final_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLNFwMjLyFa3",
        "outputId": "74786eec-83b0-4831-bef7-b98f1231901c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.055273557817908214"
            ]
          },
          "metadata": {},
          "execution_count": 400
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('model.pkl', 'wb') as file:\n",
        "    pickle.dump(model_use, file)"
      ],
      "metadata": {
        "id": "5OpIJOIckPb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('embeddings.pkl', 'wb') as file:\n",
        "    pickle.dump(updated_embeddings,file)"
      ],
      "metadata": {
        "id": "ySfsJDXKkuoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_embeddings = copy.deepcopy(normalized_glove_embeddings)\n",
        "for word in updated_embeddings.keys():\n",
        "  final_embeddings[word] = updated_embeddings[word]"
      ],
      "metadata": {
        "id": "qpH8MrExU7H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_weat(embeddings, target_set, attribute_sets):\n",
        "    # Define gendered attribute sets\n",
        "    attribute_A, attribute_B = attribute_sets\n",
        "\n",
        "    # Helper function to calculate average cosine similarity of target to an attribute set\n",
        "    def association(target_vector, attribute_set_vectors):\n",
        "        return np.mean([np.dot(target_vector, attr_vec) for attr_vec in attribute_set_vectors])\n",
        "\n",
        "    # Calculate WEAT score\n",
        "    weat_score = 0\n",
        "    attribute_A_vectors = [embeddings.get(word, np.zeros(300)) for word in attribute_A]\n",
        "    attribute_B_vectors = [embeddings.get(word, np.zeros(300)) for word in attribute_B]\n",
        "\n",
        "    for word in target_set:\n",
        "        word_vec = embeddings.get(word, np.zeros(300))\n",
        "        weat_score += association(word_vec, attribute_A_vectors) - association(word_vec, attribute_B_vectors)\n",
        "\n",
        "    return weat_score\n",
        "\n",
        "# Example occupation words list\n",
        "occupation_words = [word for word in updated_embeddings]\n",
        "\n",
        "# Define gendered word lists\n",
        "gendered_words_male = [\"he\", \"him\", \"his\", \"man\", \"male\"]\n",
        "gendered_words_female = [\"she\", \"her\", \"hers\", \"woman\", \"female\"]\n",
        "\n",
        "# Define the target and attribute sets\n",
        "target_set = occupation_words\n",
        "attribute_sets = [gendered_words_male, gendered_words_female]\n",
        "\n",
        "# Calculate the WEAT score\n",
        "weat_score = calculate_weat(updated_embeddings, target_set, attribute_sets)\n",
        "print(\"WEAT Score:\", weat_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1qXSNVDiKFM",
        "outputId": "c22e9804-061d-4c9e-8ac0-e7dbbd4cfdb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WEAT Score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weat_score = calculate_weat(normalized_glove_embeddings, target_set, attribute_sets)\n",
        "print(\"WEAT Score:\", weat_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK_LRousifeX",
        "outputId": "e91374f0-593c-4b78-aa2d-4cad23497714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WEAT Score: -0.5812739068642259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weat_score = calculate_weat(debiased_embeddings, target_set, attribute_sets)\n",
        "print(\"WEAT Score:\", weat_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4fMDS48iw6-",
        "outputId": "820491a7-925f-4ec8-c1a0-d731923309a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WEAT Score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nc8eSxHEWHCT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}